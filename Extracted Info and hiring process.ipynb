{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25904311",
   "metadata": {},
   "source": [
    "# Extracting Text from Resumes\n",
    "The first step in resume parsing is to extract the text from resumes in various formats, such as PDF or Word documents. We’ll be using the pdfminer.six library to extract text from PDF resumes. Here’s a function that takes a PDF file path as input and returns the extracted text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "989ca33e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pdfminer\n",
      "  Downloading pdfminer-20191125.tar.gz (4.2 MB)\n",
      "     ---------------------------------------- 0.0/4.2 MB ? eta -:--:--\n",
      "     - -------------------------------------- 0.1/4.2 MB 3.6 MB/s eta 0:00:02\n",
      "     ------ --------------------------------- 0.7/4.2 MB 9.2 MB/s eta 0:00:01\n",
      "     --------------------- ------------------ 2.2/4.2 MB 20.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  4.2/4.2 MB 26.7 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 4.2/4.2 MB 24.2 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting pycryptodome (from pdfminer)\n",
      "  Obtaining dependency information for pycryptodome from https://files.pythonhosted.org/packages/1f/90/d131c0eb643290230dfa4108b7c2d135122d88b714ad241d77beb4782a76/pycryptodome-3.20.0-cp35-abi3-win_amd64.whl.metadata\n",
      "  Downloading pycryptodome-3.20.0-cp35-abi3-win_amd64.whl.metadata (3.4 kB)\n",
      "Downloading pycryptodome-3.20.0-cp35-abi3-win_amd64.whl (1.8 MB)\n",
      "   ---------------------------------------- 0.0/1.8 MB ? eta -:--:--\n",
      "   ----------------------- ---------------- 1.0/1.8 MB 68.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.8/1.8 MB 22.4 MB/s eta 0:00:00\n",
      "Building wheels for collected packages: pdfminer\n",
      "  Building wheel for pdfminer (setup.py): started\n",
      "  Building wheel for pdfminer (setup.py): finished with status 'done'\n",
      "  Created wheel for pdfminer: filename=pdfminer-20191125-py3-none-any.whl size=6140156 sha256=d67b7165fb0b8a218e609abb811871f22308e16230cfa4fc4fd58cfbbe09efe5\n",
      "  Stored in directory: c:\\users\\kteja\\appdata\\local\\pip\\cache\\wheels\\4e\\c1\\68\\f7bd0a8f514661f76b5cbe3b5f76e0033d79f1296012cbbf72\n",
      "Successfully built pdfminer\n",
      "Installing collected packages: pycryptodome, pdfminer\n",
      "Successfully installed pdfminer-20191125 pycryptodome-3.20.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install pdfminer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8454230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pdfminer.six\n",
      "  Obtaining dependency information for pdfminer.six from https://files.pythonhosted.org/packages/67/7d/44d6b90e5a293d3a975cefdc4e12a932ebba814995b2a07e37e599dd27c6/pdfminer.six-20240706-py3-none-any.whl.metadata\n",
      "  Downloading pdfminer.six-20240706-py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in c:\\users\\kteja\\anaconda3\\lib\\site-packages (from pdfminer.six) (2.0.4)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in c:\\users\\kteja\\anaconda3\\lib\\site-packages (from pdfminer.six) (39.0.1)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\kteja\\anaconda3\\lib\\site-packages (from cryptography>=36.0.0->pdfminer.six) (1.15.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\kteja\\anaconda3\\lib\\site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six) (2.21)\n",
      "Downloading pdfminer.six-20240706-py3-none-any.whl (5.6 MB)\n",
      "   ---------------------------------------- 0.0/5.6 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.2/5.6 MB 3.9 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 0.9/5.6 MB 11.4 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 2.5/5.6 MB 19.8 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 4.4/5.6 MB 27.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  5.5/5.6 MB 29.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  5.6/5.6 MB 23.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.6/5.6 MB 21.2 MB/s eta 0:00:00\n",
      "Installing collected packages: pdfminer.six\n",
      "Successfully installed pdfminer.six-20240706\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install pdfminer.six\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53e123ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Tejaswini Kallakuri \\nDallas, TX | 716-717-2706  | LinkedIn | Github | Portfolio | saitejaswini369@gmail.com \\n\\nEDUCATION \\n\\n  Master of Science: Artificial Intelligence, University at Buffalo, The State University of New York                                      June 2024                  \\n\\n•  Coursework: Machine Learning, Fundamentals of AI, Pattern Recognition, Deep Learning, \\n\\nComputer Vision and Image Processing, NLP, Robotics Algorithms, Data Intensive Computing \\n\\n  Bachelor of Technology: Electronics and Communication Engineering, Sreenidhi Institute of Science and Technology    June 2020 \\n\\n•  Coursework: Image Processing, Robotics, Data structures, Probability and Stochastic Processing \\n\\nTECHNICAL SKILLS \\n\\n   Programming Languages: C, Python, Linux, SQL \\n   Neural Network Architecture: CNN, ANN, RNN, GAN’s, Transformers \\n   ML Algorithms: Regression, Classification, Naïve Bayes, Clustering \\n   Frameworks: Pandas, NumPy, Matplotlib, Scikit-Learn, Keras, SciPy, TensorFlow, PyTorch, LLM, OpenCV, Hugging Face \\n   Tools: Power BI, Docker, MATLAB, ROS, Hadoop, Spark, Git, CUDA \\n   Cloud Services: MLOps, AWS - QuickSight, EC2, Sage Maker, DynamoDB, Lambda and Google Cloud Services, Azure \\n   Certifications: AWS Cloud Practitioner, Cloud Computing and MLOps, Python, Deep Learning, IBM-SPSS Modeler (Data Analysis) \\n\\nWORK EXPERIENCE \\n\\n  Graduate Researcher - Institute for Artificial Intelligence and Data Sciences, UB, NY \\n\\n              Aug 2023-May 2024 \\n•  Led the development of a real-time pothole detection system using YOLOv7 and PyTorch, achieving 95% accuracy in road defect \\n\\n• \\n\\nidentification through precise instance segmentation. \\nImplemented  Hugging  Face-based  MobileNetV2  and  SqueezeNet,  reducing  model  size  by  97%  through  network  pruning \\ntechniques without compromising accuracy, and enhanced processing efficiency using CUDA for deployment on edge devices. \\n\\n•  Coordinated with team of professors to conduct extensive testing under various adverse weather and lighting conditions, ensuring \\n\\nsystem robustness and a 25% increase in detection reliability, thereby improving road safety. \\n\\n Graduate Researcher - Drones Lab, University at Buffalo, NY  \\n\\n               Feb 2023-Aug 2023 \\n•  Conducted advanced research for a DARPA project, achieving 95% accuracy in identifying and classifying individuals from long \\n\\ndistances using UAV cameras or street cams based on gait key points/poses. \\n\\n•  Designed and managed a CI/CD pipeline with Google's ML Kit, TensorFlow, Keras, and Scikit-Learn for data annotation, model \\n\\ntraining, and evaluation. Presented research findings at The Center for Identification Technology Research (CITeR). \\n\\n Machine Learning Engineer – Cisco, Bangalore, India  \\n\\n                                              Jul 2020-Jul 2022 \\n•  Optimized ETL pipelines for healthcare and finance sectors using Decision Trees and Random Forests with TensorFlow, boosting \\nuser engagement by 15% and operational efficiency by 10%. Leveraged AWS (EC2, S3, SageMaker, Lambda, Redshift) to boost \\ndata processing efficiency, achieving a 30% reduction in processing time and operational costs. \\n\\n•  Automated microservices deployment  by  integrating  into  the  CI/CD  pipeline,  enhancing  efficiency by 84%.  Utilized Docker, \\nKubernetes, and GitLab, reducing manual data preprocessing by 80% through MLflow implementation, streamlining end-to-end \\nworkflows and introducing automated data quality checks with Spark. \\n\\n•  Mentored  a  team  in  using  convolutional  neural  networks  (CNNs)  for  detailed  image  analysis  and  recurrent  neural  networks \\n(RNNs) for patient data pattern recognition, reducing discrepancies by 12%. Effectively communicated complex models to non-\\ntechnical stakeholders, enhancing data-driven decision-making and operational efficiency. \\n\\n AI Research Intern - Activa Inc., Hyderabad, India  \\n\\n                                                                      Jan 2020-July 2020 \\n\\n•  Developed and deployed ML algorithms for autonomous robots equipped with 2-D and 3-D Lidars for point cloud mapping and \\n\\nobject recognition, leading to a 15% increase in the effectiveness of factory planning and reconstruction projects. \\n\\n•  Collaborated with cross-functional teams to create data pipelines that enhanced robot navigation and spatial understanding. \\n\\nPROJECTS \\n\\n  Resume Parser and Job Recommendation System - Python, NLTK, spaCy, Flask API, Random Forest                                                                                                                                                                                      \\n\\n•  Developed a resume parser with a Flask-based API, enabling users to upload resumes and automatically extract key skills, provide \\n\\njob recommendations, and categorize job industries (finance, healthcare, IT) using a random forest model. \\n\\n•  Trained the system on a dataset of 25,000 resumes, achieving high accuracy in skill extraction and job classification, enhancing \\n\\njob search efficiency for users. \\n\\n  Waze User Churn Prediction - Python, Flask API, EDA, PyTorch                                                                                                                                       \\n\\n•  Developed a Flask-based web application for Waze to predict customer churn with 93% accuracy. Performed predictive analytics \\nenabling  dynamic  user  interaction,  refining  data-driven  strategic  decision-making,  such  as  personalized  retention  offers  or \\nidentifying the right time to engage with customers to prevent churn. \\n\\n Authorship Attribution for Neural Text Generation - LSTM, LLM, NLP, Python, CNN, NLTK, spaCy, Transformers                                                                                               \\n\\n•  Employed Bi-LSTM, Stacked CNN models to distinguish between AI-generated text and human-authored text, boosting fraud \\nprevention, resulting in F-1 score of 1. Performed web scraping using python to gather AI text from GPT3 and Instruct GPT.  \\n Drowsiness Detection with OpenCV and Keras - CNN, Python, OpenCV, Keras                                                                                                     \\n\\n•  Devised CNN based drowsiness detection method trained on a diverse dataset of over 10,000 drivers, leading to a 95% detection \\n\\naccuracy rate with OpenCV's face detection and landmarks to avoid accidents by triggering alarm. \\n\\n  \\n \\n \\n                                                     \\n     \\n \\n \\n \\n \\n\\x0c\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "from pdfminer.high_level import extract_text\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    return extract_text(pdf_path)\n",
    "\n",
    "\n",
    "resume_path = \"Tejaswini_Kallakuri_Resume.pdf\"\n",
    "text = extract_text_from_pdf(resume_path)\n",
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3869cab2",
   "metadata": {},
   "source": [
    "# Extracting Contact Information\n",
    "\n",
    "\n",
    "Contact information, including phone numbers, email addresses, and physical addresses, is crucial for reaching out to potential candidates. Extracting this information accurately is an essential part of resume parsing. We can use regular expressions to match patterns and extract contact information.\n",
    "\n",
    "# Function to Extract\n",
    "\n",
    "\n",
    "Let’s define a function to extract a contact number from the resume text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4795cd19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'716-717-2706'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def extract_contact_number_from_resume(text):\n",
    "    contact_number = None\n",
    "\n",
    "    # Use regex pattern to find a potential contact number\n",
    "    pattern = r\"\\b(?:\\+?\\d{1,3}[-.\\s]?)?\\(?\\d{3}\\)?[-.\\s]?\\d{3}[-.\\s]?\\d{4}\\b\"\n",
    "    match = re.search(pattern, text)\n",
    "    if match:\n",
    "        contact_number = match.group()\n",
    "\n",
    "    return contact_number\n",
    "\n",
    "phone = extract_contact_number_from_resume(text)\n",
    "phone"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ce6ac7",
   "metadata": {},
   "source": [
    "# Extracting Email Address\n",
    "In addition to the contact number, extracting the email address is vital for communication with candidates. We can again use regular expressions to match patterns and extract the email address. Here’s a function to extract the email address from the resume text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1bc1e09c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'saitejaswini369@gmail.com'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def extract_email_from_resume(text):\n",
    "    email = None\n",
    "\n",
    "    # Use regex pattern to find a potential email address\n",
    "    pattern = r\"\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Za-z]{2,}\\b\"\n",
    "    match = re.search(pattern, text)\n",
    "    if match:\n",
    "        email = match.group()\n",
    "\n",
    "    return email\n",
    "\n",
    "email = extract_email_from_resume(text)\n",
    "email"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74a16b8",
   "metadata": {},
   "source": [
    "# Extracting Skills\n",
    "Identifying the skills mentioned in a resume is crucial for determining the candidate’s qualifications. We can create a list of relevant skills and match them against the resume text to extract the mentioned skills. Let’s define a function to extract skills from the resume text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dbb25dda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skills: ['Python', 'Data Analysis', 'Machine Learning', 'Communication', 'Deep Learning', 'SQL', 'Git', 'Research', 'SPSS', 'Matplotlib', 'Pandas', 'Numpy', 'Scikit-learn', 'TensorFlow', 'Keras', 'PyTorch', 'NLTK', 'Computer Vision', 'Image Processing', 'Random Forest', 'Decision Trees', 'ETL', 'Cloud Computing', 'Docker', 'Kubernetes', 'Linux', 'CI/CD', 'Power BI', 'ETL', 'Data Quality', 'Predictive Analytics', 'Web Scraping', 'Microservices', 'Flask']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def extract_skills_from_resume(text, skills_list):\n",
    "    skills = []\n",
    "\n",
    "    for skill in skills_list:\n",
    "        pattern = r\"\\b{}\\b\".format(re.escape(skill))\n",
    "        match = re.search(pattern, text, re.IGNORECASE)\n",
    "        if match:\n",
    "            skills.append(skill)\n",
    "\n",
    "    return skills\n",
    "\n",
    "\n",
    "# List of predefined skills\n",
    "skills_list = [\n",
    "    'Python', 'Data Analysis', 'Machine Learning', 'Communication', 'Project Management', 'Deep Learning', 'SQL', 'Tableau',\n",
    "    'Java', 'C++', 'JavaScript', 'HTML', 'CSS', 'React', 'Angular', 'Node.js', 'MongoDB', 'Express.js', 'Git',\n",
    "    'Research', 'Statistics', 'Quantitative Analysis', 'Qualitative Analysis', 'SPSS', 'R', 'Data Visualization', 'Matplotlib',\n",
    "    'Seaborn', 'Plotly', 'Pandas', 'Numpy', 'Scikit-learn', 'TensorFlow', 'Keras', 'PyTorch', 'NLTK', 'Text Mining',\n",
    "    'Natural Language Processing', 'Computer Vision', 'Image Processing', 'OCR', 'Speech Recognition', 'Recommendation Systems',\n",
    "    'Collaborative Filtering', 'Content-Based Filtering', 'Reinforcement Learning', 'Neural Networks', 'Convolutional Neural Networks',\n",
    "    'Recurrent Neural Networks', 'Generative Adversarial Networks', 'XGBoost', 'Random Forest', 'Decision Trees', 'Support Vector Machines',\n",
    "    'Linear Regression', 'Logistic Regression', 'K-Means Clustering', 'Hierarchical Clustering', 'DBSCAN', 'Association Rule Learning',\n",
    "    'Apache Hadoop', 'Apache Spark', 'MapReduce', 'Hive', 'HBase', 'Apache Kafka', 'Data Warehousing', 'ETL', 'Big Data Analytics',\n",
    "    'Cloud Computing', 'Amazon Web Services (AWS)', 'Microsoft Azure', 'Google Cloud Platform (GCP)', 'Docker', 'Kubernetes', 'Linux',\n",
    "    'Shell Scripting', 'Cybersecurity', 'Network Security', 'Penetration Testing', 'Firewalls', 'Encryption', 'Malware Analysis',\n",
    "    'Digital Forensics', 'CI/CD', 'DevOps', 'Agile Methodology', 'Scrum', 'Kanban', 'Continuous Integration', 'Continuous Deployment',\n",
    "    'Software Development', 'Web Development', 'Mobile Development', 'Backend Development', 'Frontend Development', 'Full-Stack Development',\n",
    "    'UI/UX Design', 'Responsive Design', 'Wireframing', 'Prototyping', 'User Testing', 'Adobe Creative Suite', 'Photoshop', 'Illustrator',\n",
    "    'InDesign', 'Figma', 'Sketch', 'Zeplin', 'InVision', 'Product Management', 'Market Research', 'Customer Development', 'Lean Startup',\n",
    "    'Business Development', 'Sales', 'Marketing', 'Content Marketing', 'Social Media Marketing', 'Email Marketing', 'SEO', 'SEM', 'PPC',\n",
    "    'Google Analytics', 'Facebook Ads', 'LinkedIn Ads', 'Lead Generation', 'Customer Relationship Management (CRM)', 'Salesforce',\n",
    "    'HubSpot', 'Zendesk', 'Intercom', 'Customer Support', 'Technical Support', 'Troubleshooting', 'Ticketing Systems', 'ServiceNow',\n",
    "    'ITIL', 'Quality Assurance', 'Manual Testing', 'Automated Testing', 'Selenium', 'JUnit', 'Load Testing', 'Performance Testing',\n",
    "    'Regression Testing', 'Black Box Testing', 'White Box Testing', 'API Testing', 'Mobile Testing', 'Usability Testing', 'Accessibility Testing',\n",
    "    'Cross-Browser Testing', 'Agile Testing', 'User Acceptance Testing', 'Software Documentation', 'Technical Writing', 'Copywriting',\n",
    "    'Editing', 'Proofreading', 'Content Management Systems (CMS)', 'WordPress', 'Joomla', 'Drupal', 'Magento', 'Shopify', 'E-commerce',\n",
    "    'Payment Gateways', 'Inventory Management', 'Supply Chain Management', 'Logistics', 'Procurement', 'ERP Systems', 'SAP', 'Oracle',\n",
    "    'Microsoft Dynamics', 'Tableau', 'Power BI', 'QlikView', 'Looker', 'Data Warehousing', 'ETL', 'Data Engineering', 'Data Governance',\n",
    "    'Data Quality', 'Master Data Management', 'Predictive Analytics', 'Prescriptive Analytics', 'Descriptive Analytics', 'Business Intelligence',\n",
    "    'Dashboarding', 'Reporting', 'Data Mining', 'Web Scraping', 'API Integration', 'RESTful APIs', 'GraphQL', 'SOAP', 'Microservices',\n",
    "    'Serverless Architecture', 'Lambda Functions', 'Event-Driven Architecture', 'Message Queues', 'GraphQL', 'Socket.io', 'WebSockets'\n",
    "'Ruby', 'Ruby on Rails', 'PHP', 'Symfony', 'Laravel', 'CakePHP', 'Zend Framework', 'ASP.NET', 'C#', 'VB.NET', 'ASP.NET MVC', 'Entity Framework',\n",
    "    'Spring', 'Hibernate', 'Struts', 'Kotlin', 'Swift', 'Objective-C', 'iOS Development', 'Android Development', 'Flutter', 'React Native', 'Ionic',\n",
    "    'Mobile UI/UX Design', 'Material Design', 'SwiftUI', 'RxJava', 'RxSwift', 'Django', 'Flask', 'FastAPI', 'Falcon', 'Tornado', 'WebSockets',\n",
    "    'GraphQL', 'RESTful Web Services', 'SOAP', 'Microservices Architecture', 'Serverless Computing', 'AWS Lambda', 'Google Cloud Functions',\n",
    "    'Azure Functions', 'Server Administration', 'System Administration', 'Network Administration', 'Database Administration', 'MySQL', 'PostgreSQL',\n",
    "    'SQLite', 'Microsoft SQL Server', 'Oracle Database', 'NoSQL', 'MongoDB', 'Cassandra', 'Redis', 'Elasticsearch', 'Firebase', 'Google Analytics',\n",
    "    'Google Tag Manager', 'Adobe Analytics', 'Marketing Automation', 'Customer Data Platforms', 'Segment', 'Salesforce Marketing Cloud', 'HubSpot CRM',\n",
    "    'Zapier', 'IFTTT', 'Workflow Automation', 'Robotic Process Automation (RPA)', 'UI Automation', 'Natural Language Generation (NLG)',\n",
    "    'Virtual Reality (VR)', 'Augmented Reality (AR)', 'Mixed Reality (MR)', 'Unity', 'Unreal Engine', '3D Modeling', 'Animation', 'Motion Graphics',\n",
    "    'Game Design', 'Game Development', 'Level Design', 'Unity3D', 'Unreal Engine 4', 'Blender', 'Maya', 'Adobe After Effects', 'Adobe Premiere Pro',\n",
    "    'Final Cut Pro', 'Video Editing', 'Audio Editing', 'Sound Design', 'Music Production', 'Digital Marketing', 'Content Strategy', 'Conversion Rate Optimization (CRO)',\n",
    "    'A/B Testing', 'Customer Experience (CX)', 'User Experience (UX)', 'User Interface (UI)', 'Persona Development', 'User Journey Mapping', 'Information Architecture (IA)',\n",
    "    'Wireframing', 'Prototyping', 'Usability Testing', 'Accessibility Compliance', 'Internationalization (I18n)', 'Localization (L10n)', 'Voice User Interface (VUI)',\n",
    "    'Chatbots', 'Natural Language Understanding (NLU)', 'Speech Synthesis', 'Emotion Detection', 'Sentiment Analysis', 'Image Recognition', 'Object Detection',\n",
    "    'Facial Recognition', 'Gesture Recognition', 'Document Recognition', 'Fraud Detection', 'Cyber Threat Intelligence', 'Security Information and Event Management (SIEM)',\n",
    "    'Vulnerability Assessment', 'Incident Response', 'Forensic Analysis', 'Security Operations Center (SOC)', 'Identity and Access Management (IAM)', 'Single Sign-On (SSO)',\n",
    "    'Multi-Factor Authentication (MFA)', 'Blockchain', 'Cryptocurrency', 'Decentralized Finance (DeFi)', 'Smart Contracts', 'Web3', 'Non-Fungible Tokens (NFTs)']\n",
    "\n",
    "extracted_skills = extract_skills_from_resume(text, skills_list)\n",
    "\n",
    "if extracted_skills:\n",
    "    print(\"Skills:\", extracted_skills)\n",
    "else:\n",
    "    print(\"No skills found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cfb5931",
   "metadata": {},
   "source": [
    "# Extracting Education\n",
    "Education qualifications play a vital role in the recruitment process. We can match specific education keywords against the resume text to identify the candidate’s educational background. Here’s a function to extract education information from the resume text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "544f6bc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Education: ['finance', 'Architecture', 'EDUCATION']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def extract_education_from_resume(text):\n",
    "    education = []\n",
    "\n",
    "    # List of education keywords to match against\n",
    "    education_keywords = [\n",
    "        'Computer Science', 'Information Technology', 'Software Engineering', 'Electrical Engineering', 'Mechanical Engineering', 'Civil Engineering',\n",
    "        'Chemical Engineering', 'Biomedical Engineering', 'Aerospace Engineering', 'Nuclear Engineering', 'Industrial Engineering', 'Systems Engineering',\n",
    "        'Environmental Engineering', 'Petroleum Engineering', 'Geological Engineering', 'Marine Engineering', 'Robotics Engineering', 'Biotechnology',\n",
    "        'Biochemistry', 'Microbiology', 'Genetics', 'Molecular Biology', 'Bioinformatics', 'Neuroscience', 'Biophysics', 'Biostatistics', 'Pharmacology',\n",
    "        'Physiology', 'Anatomy', 'Pathology', 'Immunology', 'Epidemiology', 'Public Health', 'Health Administration', 'Nursing', 'Medicine', 'Dentistry',\n",
    "        'Pharmacy', 'Veterinary Medicine', 'Medical Technology', 'Radiography', 'Physical Therapy', 'Occupational Therapy', 'Speech Therapy', 'Nutrition',\n",
    "        'Sports Science', 'Kinesiology', 'Exercise Physiology', 'Sports Medicine', 'Rehabilitation Science', 'Psychology', 'Counseling', 'Social Work',\n",
    "        'Sociology', 'Anthropology', 'Criminal Justice', 'Political Science', 'International Relations', 'Economics', 'Finance', 'Accounting', 'Business Administration',\n",
    "        'Management', 'Marketing', 'Entrepreneurship', 'Hospitality Management', 'Tourism Management', 'Supply Chain Management', 'Logistics Management',\n",
    "        'Operations Management', 'Human Resource Management', 'Organizational Behavior', 'Project Management', 'Quality Management', 'Risk Management',\n",
    "        'Strategic Management', 'Public Administration', 'Urban Planning', 'Architecture', 'Interior Design', 'Landscape Architecture', 'Fine Arts',\n",
    "        'Visual Arts', 'Graphic Design', 'Fashion Design', 'Industrial Design', 'Product Design', 'Animation', 'Film Studies', 'Media Studies',\n",
    "        'Communication Studies', 'Journalism', 'Broadcasting', 'Creative Writing', 'English Literature', 'Linguistics', 'Translation Studies',\n",
    "        'Foreign Languages', 'Modern Languages', 'Classical Studies', 'History', 'Archaeology', 'Philosophy', 'Theology', 'Religious Studies',\n",
    "        'Ethics', 'Education', 'Early Childhood Education', 'Elementary Education', 'Secondary Education', 'Special Education', 'Higher Education',\n",
    "        'Adult Education', 'Distance Education', 'Online Education', 'Instructional Design', 'Curriculum Development'\n",
    "        'Library Science', 'Information Science', 'Computer Engineering', 'Software Development', 'Cybersecurity', 'Information Security',\n",
    "        'Network Engineering', 'Data Science', 'Data Analytics', 'Business Analytics', 'Operations Research', 'Decision Sciences',\n",
    "        'Human-Computer Interaction', 'User Experience Design', 'User Interface Design', 'Digital Marketing', 'Content Strategy',\n",
    "        'Brand Management', 'Public Relations', 'Corporate Communications', 'Media Production', 'Digital Media', 'Web Development',\n",
    "        'Mobile App Development', 'Game Development', 'Virtual Reality', 'Augmented Reality', 'Blockchain Technology', 'Cryptocurrency',\n",
    "        'Digital Forensics', 'Forensic Science', 'Criminalistics', 'Crime Scene Investigation', 'Emergency Management', 'Fire Science',\n",
    "        'Environmental Science', 'Climate Science', 'Meteorology', 'Geography', 'Geomatics', 'Remote Sensing', 'Geoinformatics',\n",
    "        'Cartography', 'GIS (Geographic Information Systems)', 'Environmental Management', 'Sustainability Studies', 'Renewable Energy',\n",
    "        'Green Technology', 'Ecology', 'Conservation Biology', 'Wildlife Biology', 'Zoology']\n",
    "\n",
    "    for keyword in education_keywords:\n",
    "        pattern = r\"(?i)\\b{}\\b\".format(re.escape(keyword))\n",
    "        match = re.search(pattern, text)\n",
    "        if match:\n",
    "            education.append(match.group())\n",
    "\n",
    "    return education\n",
    "\n",
    "extracted_education = extract_education_from_resume(text)\n",
    "if extracted_education:\n",
    "    print(\"Education:\", extracted_education)\n",
    "else:\n",
    "    print(\"No education information found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0951159a",
   "metadata": {},
   "source": [
    "# Extracting Name Using spaCy\n",
    "Identifying the candidate’s name from the resume is essential for personalization and identification. We can use spaCy and its pattern matching capabilities to extract the candidate’s name. Let’s define a function to extract the name using spaCy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9c0bf68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Tejaswini Kallakuri\n"
     ]
    }
   ],
   "source": [
    "def extract_name_from_resume(text):\n",
    "    name = None\n",
    "\n",
    "    # Use regex pattern to find a potential name\n",
    "    pattern = r\"(\\b[A-Z][a-z]+\\b)\\s(\\b[A-Z][a-z]+\\b)\"\n",
    "    match = re.search(pattern, text)\n",
    "    if match:\n",
    "        name = match.group()\n",
    "\n",
    "    return name\n",
    "\n",
    "name = extract_name_from_resume(text)\n",
    "\n",
    "if name:\n",
    "    print(\"Name:\", name)\n",
    "else:\n",
    "    print(\"Name not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420503a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
